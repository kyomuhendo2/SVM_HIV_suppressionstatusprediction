{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923659ed-6e3b-42fb-81c8-101e49231c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93374002-a2b4-4761-b0fd-ce56df88d528",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Loading the Dataset\n",
    "data = pd.read_csv('Data/Clean_Dataset.csv')\n",
    "print(data)\n",
    "\n",
    "\n",
    "#Data Distribution\n",
    "# Count of each class in the target variable\n",
    "print(data['Suppression Status'].value_counts())\n",
    "\n",
    "# Plot class distribution\n",
    "sns.countplot(x='Suppression Status', data=data)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Suppression Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Relationship between weight and suppression status\n",
    "pd.crosstab(data['Age'], data['Suppression Status']).plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Age vs Suppression Status')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Relationship between weight and suppression status\n",
    "pd.crosstab(data['Years on ART'], data['Suppression Status']).plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Years on ART vs Suppression Status')\n",
    "plt.xlabel('Years on ART')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Choosing Age and Years on ART as the features\n",
    "X = data[['Age', 'Years on ART']]\n",
    "y = data['Suppression Status']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the SVM classifier with an sigmoid kernel\n",
    "svm_model = SVC(kernel='linear', probability=True, class_weight='balanced', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Create a meshgrid to plot decision boundary\n",
    "h = .02  # Step size in the mesh\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict on the meshgrid\n",
    "Z = svm_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o', s=100, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot the test points\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolors='k', marker='x', s=100, cmap=plt.cm.Paired)\n",
    "\n",
    "plt.title(\"SVM Decision Boundary with 'Age' and 'Years on ART'\")\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Years on ART')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6795865b-caf3-4a82-bf56-fc6954370089",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"Predictions made\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3c512-e503-43dd-9376-2628c00ba4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [[27, 3]] \n",
    "\n",
    "# Example: Age = 70, Years on ART = 3\n",
    "\n",
    "# Scale the new data using the same scaler used for training\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Make the prediction\n",
    "new_prediction = svm_model.predict(new_data_scaled)\n",
    "\n",
    "\n",
    "print(\"Prediction for the new data:\", new_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ccd57-5aad-45db-b405-04aa899cd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "# Prediction using the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
